# -*- coding: utf-8 -*-
"""CNN_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G0UxDYfuNgeLHCsgsp824u4ELqC5Uisz
"""

# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import PIL as pl
import random
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.utils import image_dataset_from_directory, img_to_array
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, AvgPool2D, MaxPooling2D, Flatten, Dense, Dropout

import os
import warnings

# Suppress warnings
warnings.filterwarnings('ignore')

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Dataset path (adjust to your dataset's location)
dataset_path = '/content/drive/MyDrive/Colab Notebooks/Data1'

# List all files in the dataset directory
for dirname, _, filenames in os.walk(dataset_path):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Ensure necessary libraries are installed
!pip install opencv-python-headless Pillow tensorflow

import cv2
import matplotlib.pyplot as plt

# Load the image using cv2
img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Data1/train/Bengin cases/Bengin case (10).jpg')

# Convert the image from BGR to RGB for proper display in matplotlib
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Display the image with matplotlib
plt.figure(figsize=(8, 8))
plt.title('Benign Case')
plt.imshow(img_rgb)
plt.axis('off')  # Turn off axis for better display
plt.show()

# Load the image using cv2
img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Data1/train/Malignant cases/Malignant case (10).jpg')

# Convert the image from BGR to RGB for proper display in matplotlib
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Display the image with matplotlib
plt.figure(figsize=(8, 8))
plt.title('Malignant Case')
plt.imshow(img_rgb)
plt.axis('off')  # Turn off axis for better display
plt.show()

# Load the image using cv2
img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/Data1/train/Normal cases/Normal case (100).jpg')

# Convert the image from BGR to RGB for proper display in matplotlib
img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Display the image with matplotlib
plt.figure(figsize=(8, 8))
plt.title('Normal Case')
plt.imshow(img_rgb)
plt.axis('off')  # Turn off axis for better display
plt.show()

img.shape

dir = '/content/drive/MyDrive/Colab Notebooks/Data1/train'
img_width = 256
img_height = 256



# Second section of the path
categories = ['Bengin cases', 'Malignant cases', 'Normal cases']

# Now we get the images using complete path and store the images into img_data folder.
img_data = []
for cata in categories:
    folder = os.path.join(dir, cata)
    label = categories.index(cata)
    for img in os.listdir(folder):
        img_path = os.path.join(folder, img)

        try:
            # Attempt to read and resize the image
            img_array = cv2.imread(img_path)
            img_array = cv2.resize(img_array, (img_height, img_width))

            # Check if the image array is not empty
            if img_array is not None and not img_array.size == 0:
                img_data.append([img_array, label])

        except Exception as e:
            continue


random.shuffle(img_data)

x=[]
y=[]
for features,labels in img_data:
    x.append(features)
    y.append(labels)

#Convert X and Y list into array
X=np.array(x, dtype = float)
Y=np.array(y, dtype = float)

print(X[19])

# normalization
for i in range(len(X)):
    X[i] = X[i]/255.0

X.shape

x, x_test, y, y_test = train_test_split(X, Y, test_size = 0.2)

x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.2)

model = Sequential()

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np

# Define the ImageDataGenerator for data augmentation
datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Define the number of augmented images per original image
augmented_images_per_original = 6

# Initialize lists for augmented data
augmented_x_train = []
augmented_y_train = []

# Generate augmented images in batches
batch_size = 32  # Adjust based on your system's memory
for start in range(0, len(x_train), batch_size):
    end = min(start + batch_size, len(x_train))
    batch_x = x_train[start:end]
    batch_y = y_train[start:end]

    # Repeat each image in the batch to generate multiple augmentations
    repeated_batch_x = np.repeat(batch_x, augmented_images_per_original, axis=0)
    repeated_batch_y = np.repeat(batch_y, augmented_images_per_original, axis=0)

    # Generate augmented data
    augmented_batch = datagen.flow(repeated_batch_x, batch_size=batch_size, shuffle=False)
    for augmented_images in augmented_batch:
        augmented_x_train.extend(augmented_images)
        augmented_y_train.extend(repeated_batch_y[:len(augmented_images)])
        if len(augmented_x_train) >= len(repeated_batch_x):
            break

# Convert augmented data lists to numpy arrays
augmented_x_train = np.array(augmented_x_train)
augmented_y_train = np.array(augmented_y_train)

# Concatenate original and augmented data
x_train_augmented = np.concatenate((x_train, augmented_x_train), axis=0)
y_train_augmented = np.concatenate((y_train, augmented_y_train), axis=0)

print(f"Augmented training data shape: {x_train_augmented.shape}")
print(f"Augmented labels shape: {y_train_augmented.shape}")

model.add(Conv2D(128, (3, 3), padding = 'same', input_shape = X.shape[1: ], activation = 'relu'))
model.add(AvgPool2D(2,2))
model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))
model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))
model.add(MaxPooling2D(2,2))
model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))
model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))

model.add(MaxPooling2D(2,2))
model.add(Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))
model.add(Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))

model.add(MaxPooling2D(2,2))
model.add(Flatten())
model.add(Dropout(0.2, seed = 12))
model.add(Dense(3000, activation = 'relu'))
model.add(Dense(1500, activation = 'relu'))
model.add(Dense(3, activation = 'softmax'))

model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])

model.summary()

# Import EarlyStopping callback
from tensorflow.keras.callbacks import EarlyStopping

# Define EarlyStopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)

history = model.fit(x_train, y_train, validation_data = (x_val, y_val),epochs = 15)

model.save('/content/drive/MyDrive/Colab Notebooks/lung_cancer_detection_model.h5')

result = model.predict(x_test)

test_loss, test_accuracy = model.evaluate(x_test, y_test)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

plt.plot(history.history['accuracy'], label = 'Train accuracy')
plt.plot(history.history['val_accuracy'], label = 'val accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc = 'best')

plt.plot(history.history['loss'], label = 'Train Loss')
plt.plot(history.history['val_loss'], label = 'Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(loc = 'best')

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Define image path
image_path = '/content/drive/MyDrive/Colab Notebooks/Data1/test/BenginCases/Bengin case (105).jpg'

# Load the test image
img = cv2.imread(image_path)

# Check if the image was loaded successfully
if img is None:
    print(f"Error: Unable to load image at {image_path}. Please check the file path.")
else:
    # Resize the image
    img = cv2.resize(img, (img_height, img_width))

    # Expand dimensions to create a batch of size 1
    img = np.expand_dims(img, axis=0)

    # Make prediction
    prediction = model.predict(img)

    # Interpret prediction
    class_label = np.argmax(prediction)
    confidence = prediction[0][class_label]

    print("Predicted Class Label:", class_label)
    print("Confidence:", confidence)

    # Mapping class labels to categories
    class_labels_to_categories = {0: 'Benign', 1: 'Malignant', 2: 'Normal'}

    # Display the predicted category
    predicted_category = class_labels_to_categories[class_label]
    print("Predicted Category:", predicted_category)

    # Display the image with prediction
    img_display = cv2.imread(image_path)
    plt.imshow(cv2.cvtColor(img_display, cv2.COLOR_BGR2RGB))
    plt.axis('off')
    plt.title(predicted_category)
    plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import load_img, img_to_array


# Load the test image
image_path = '/content/drive/MyDrive/Colab Notebooks/Data1/test/MalignantCases/Malignant case (464).jpg'
img = cv2.imread(image_path)

img = cv2.resize(img, (img_height, img_width))

# Expand dimensions to create a batch of size 1
img = np.expand_dims(img, axis=0)

# Make prediction
prediction = model.predict(img)

# Interpret prediction
class_label = np.argmax(prediction)
confidence = prediction[0][class_label]


print("Predicted Class Label:", class_label)
print("Confidence:", confidence)

# Mapping class labels to categories
class_labels_to_categories = {0: 'Benign', 1: 'Malignant', 2: 'Normal'}

# Display the predicted category
predicted_category = class_labels_to_categories[class_label]
print("Predicted Category:", predicted_category)

img = cv2.imread(image_path)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title(predicted_category)
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load the test image
image_path = '/content/drive/MyDrive/Colab Notebooks/Data1/test/normal/Normal case (42).jpg'
img = cv2.imread(image_path)


img = cv2.resize(img, (img_height, img_width))

# Expand dimensions to create a batch of size 1
img = np.expand_dims(img, axis=0)

# Make prediction
prediction = model.predict(img)

# Interpret prediction
class_label = np.argmax(prediction)
confidence = prediction[0][class_label]

print("Predicted Class Label:", class_label)
print("Confidence:", confidence)

# Mapping class labels to categories
class_labels_to_categories = {0: 'Benign', 1: 'Malignant', 2: 'Normal'}

# Display the predicted category
predicted_category = class_labels_to_categories[class_label]
print("Predicted Category:", predicted_category)

img = cv2.imread(image_path)

plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title(predicted_category)
plt.show()

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Define true labels and predicted labels
true_labels = y_test
predicted_labels = np.argmax(result, axis=1)

# Calculate confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_labels_to_categories.values(),
            yticklabels=class_labels_to_categories.values())
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()